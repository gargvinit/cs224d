<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400' rel='stylesheet' type='text/css'>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<title>Opinion Mining with Deep Recurrent Neural Networks</title>
<link rel="stylesheet" type="text/css" href="main.css">
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-38628278-1', 'cornell.edu');
  ga('send', 'pageview');

</script>
<body>
<table width="626" height="429" border="0">
  <tbody><tr>
    <td width="216" height="63">&nbsp;</td>
    <td width="410"><span class="hd">opinion mining with deep recurrent nets
      </span>
      <div>
        <div></div>
      </div></td>
  </tr>
  <tr>
    <td rowspan="2" align="right" valign="top">
    <span class="para"><a href="default.htm">back</a></span> &nbsp</td>
    
  </tr>
  <tr>
    <td height="248" valign="top">
<span class="para">
<b>Paper</b> : <a href="http://www.cs.cornell.edu/~oirsoy/files/emnlp14drnt.pdf">Opinion Mining with Deep Recurrent Neural Networks</a></span><br>
<em class="pauthor">O. Irsoy, C. Cardie</em>
<span class="pvenue">EMNLP, 2014, Doha, Qatar.</span><br><br>
    
<span class="para">
<b>Abstract</b>
: Recurrent neural networks (RNNs) are connectionist models of sequential data
that are naturally applicable to the analysis of natural language.
Recently, ``depth in space" --- as an orthogonal notion to ``depth
in time" --- in RNNs has been investigated by stacking multiple layers
of RNNs and shown empirically to bring a temporal hierarchy
to the architecture. In this work we apply these deep RNNs to the task of
opinion expression extraction formulated as a token-level sequence-labeling 
task. Experimental results show that deep, narrow RNNs outperform
traditional shallow, wide RNNs with the same number of parameters. Furthermore, 
our approach outperforms previous CRF-based baselines, including
the state-of-the-art semi-Markov CRF model, and does so
without access to the powerful opinion lexicons and syntactic features
relied upon by the semi-CRF, as well as without the standard
layer-by-layer pre-training typically required of RNN architectures.
<br><br>

<b>Slides</b> : Oral presentation is <a href="files/mpqa-drnt/emnlp14talk-irsoy.pdf">here</a>.<br><br>

<b>More slides</b> : Part of <a href="files/cornellai14.pdf">this</a> talk I gave at Cornell AI seminar was based on
this work.<br><br>

<b>Code</b> : My C++ code is <a href="https://github.com/oir/deep-recurrent">here</a>. Please cite the paper if you use it.<br><br>

<b>Data</b> : Preprocessed version of the dataset is <a href="files/mpqa-drnt/mpqa-opexps.tar.gz">here</a>, which you can use to replicate the results. The original MPQA corpus can be found <a href="http://mpqa.cs.pitt.edu/corpora/mpqa_corpus/">here</a>. You should cite the appropriate paper by Wiebe et al (2005) if you use the data. <br><br> <br><br> 


<b>Bibtex</b>:<br>
</span>
<span class=code>
@InProceedings{irsoy-drnt,<br>
  &nbsp;&nbsp;author    = {\.Irsoy, Ozan and Cardie, Claire},<br>
  &nbsp;&nbsp;title     = {Opinion Mining with Deep Recurrent Neural Networks},<br>
  &nbsp;&nbsp;booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},<br>
  &nbsp;&nbsp;pages     = {720--728},<br>
  &nbsp;&nbsp;year      = {2014},<br>
  &nbsp;&nbsp;location  = {Doha, Qatar},<br>
  &nbsp;&nbsp;url       = {http://aclweb.org/anthology/D14-1080}<br>
}
</span>


    
      
    </td>
  </tr>
</tbody></table>




</body></html>
